# Enumeration
Attacks on a web application is quite dependent on the technology stack in use:
-   Programming language and frameworks
-   Web server software
-   Database software
-   Server operating system

Firefox is the default browser in Linux, and can be used to gather the above information.

# Inspecting URLS
File extensions (which are sometimes part of the URL) can reveal the **programming language** the application was written in. Some of these, like **.php**, are straightforward, but other extensions are more cryptic and vary based on the frameworks in use. For example, a Java-based web application might use **.jsp**, **.do**, or **.html**.

However, since many languages and framworks support the concept of routes (which allow developers to map a URI to a section of code), file extensions in URLs are becoming less common.

# Inspecting Page Content
We can use the *Debugger* tool within the *Web Developer* menu in Firefox to display the page's resources and discover any Javascript frameworks being used on the page. `Ctrl + Shift + K` opens the *Web Developer* menu.

We can use *PrettyPrint*to view the code in an easier format to read. (Highlighted in below screenshot)
![[Pasted image 20221214174112.png]]

# Viewing Response Headers
We can also intercept and inspect the server's responses for additional information. As a basic, we can use the *Network* tool in the *Web Developer* menu in Firefox to do so.

The headers that start with "X-" are non-standard HTTP headers, which may reveal additional information about hte technology stack used by the application. Some examples of non-standard headers include _X-Powered-By_, _x-amz-cf-id_, and _X-Aspnet-Version_. Further research into these names could reveal additional information, such as the "x-amz-cf-id" header, which indicates the application uses Amazon CloudFront.
![[Pasted image 20221214174641.png]]

# Inspecting Sitemaps
Web applications can also include sitemap files which help search engine bots crawl and index their sites. These files also specify what pages **not** to crawl - which is what we may be interested in.

Two most common sitemap filenames are: **robots.txt** and **sitemap.xml**
```bash
curl http://www.megacorpone.com/robots.txt
# User-agent: *
# Allow: /
# Allow: /nanites.php

```

# Locating Administrator Consoles
Web servers often ship with remote administration web applications, or consoles, which can be accessible via a particular URL and often on a specific TCP port.
Two common examples are the _manager_ application for _Tomcat_ and _phpMyAdmin for MySQL hosted at /manager/html and /phpmyadmin respectively.

***
# Topical Exercises
